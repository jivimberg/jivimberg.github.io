<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Release | Coding Forest]]></title>
  <link href="http://jivimberg.github.io/blog/categories/release/atom.xml" rel="self"/>
  <link href="http://jivimberg.github.io/"/>
  <updated>2023-05-01T19:42:54-07:00</updated>
  <id>http://jivimberg.github.io/</id>
  <author>
    <name><![CDATA[Juan Ignacio Vimberg]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[About Deploying on Fridays]]></title>
    <link href="http://jivimberg.github.io/blog/2021/01/22/about-deploying-on-fridays/"/>
    <updated>2021-01-22T08:55:35-08:00</updated>
    <id>http://jivimberg.github.io/blog/2021/01/22/about-deploying-on-fridays</id>
    <content type="html"><![CDATA[<p>Common knowledge says that you don‚Äôt deploy on Friday if you want to have a peaceful weekend. Yet, some people will tell you that if you‚Äôre not comfortable deploying every day of the week, you‚Äôre doing it wrong. They‚Äôll say that deploying shouldn‚Äôt be scary and that you probably don‚Äôt have enough tests. So, which one is it?</p>

<!--more-->


<p><img class="center" src="/images/posts/2021-01-22/homer-deploying.png" width="350"></p>

<h2>The problem with Fridays</h2>

<p>Fridays are the last day of the working week, and for many teams, it might also be the end of the sprint/cycle/iteration. Explicit or not, there‚Äôs a deadline looming between the developer and the weekend. We invested long hours on this new feature, and we just want to push it out the door, close the ticket, and come back to a clean slate on Monday. Nobody likes heading into the weekend feeling like a fraud because they couldn‚Äôt complete the planned tasks in time. The bigger the task, the more eager we are to close it.</p>

<p>So what do we do? We rush it. Maybe we skip testing in a staging environment or turn a blind eye to that flaky test that always fails, and <em>we ship it</em>. We feel the weight being lifted off our shoulders as we click deploy, and we head out the door smiling, ready to enjoy the weekend.</p>

<p>Only somebody will have to clean up our mess when things go south.</p>

<h2>When is a task completed?</h2>

<p>To understand how to combat the danger of Fridays, let‚Äôs consider the <em>software lifecycle</em>. That is, the things that happen between <em>‚ÄúI have to implement feature X‚Äù</em> and  <em>‚Äú<em>people using it in production</em>‚Äù</em>.</p>

<p><img class="center" src="/images/posts/2021-01-22/software-lifecycle1.jpeg" width="700"></p>

<p>From the developer&rsquo;s point of view, when would you say that feature X is <em>Done</em>? Is it once the branch is merged? Is it after the code is deployed? The answer depends on what your team considers the developer‚Äôs responsibility. On teams doing <a href="https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249">Full Cycle Development</a>, the same person writing the code is the one that will test, operate and deploy the service. Which means that <strong>the feature can only be marked as Done once it‚Äôs being used in production.</strong></p>

<p>Deploying is only one step, after which you <strong>release</strong> the change to some (or all) of your users and <strong>observe</strong> that it is working as intended. <em><em>Spoiler Alert</em></em> Sometimes it won‚Äôt be, and you‚Äôll have to go back to the code and add little fixes here and there.</p>

<p>Treating deployments as just another phase of the software lifecycle enables <a href="https://www.infoq.com/articles/observability-driven-development/">Observability Driven Development</a>. Letting developers <em>see</em> how their code behaves in production before closing the task.</p>

<h2>Optimizing the feedback loops</h2>

<p>The software lifecycle diagram shown above is an over-simplification. In reality, the flow is never a straight line. Every step can send you back to a previous step: Started coding and found a flaw in the design, go back to design  üîô, a test started failing, go back to develop üîô, etc.</p>

<p><img class="center" src="/images/posts/2021-01-22/software-lifecycle2.jpeg" width="700"></p>

<p><a href="https://martinfowler.com/articles/developer-effectiveness.html">The secret sauce to a highly efficient team is keeping these feedback loops as short as possible</a>. If your tests take thirty minutes to run, by the time you see the failure, you‚Äôre already deep in some other task (or worse, on your 9th YouTube video).</p>

<p>Deploying is no different. If it takes months for your code to reach production, by the time your users start using your new feature (and uncovering bugs), you have already moved on to something else. You no longer have the context fresh on your mind, and you barely recall the details and the design decisions taken at the time (which is why <a href="https://jivimberg.io/blog/2020/12/26/documenting-decisions/">you should be documenting those decisions</a>).</p>

<p><img class="center" src="/images/posts/2021-01-22/software-lifecycle3.jpeg" width="700"></p>

<h2>How to make deployments less scary</h2>

<p><strong>The single most important change you can make to have less scary deployments, is to deploy small changes. Ideally, deploying one change at a time. One Pull Request ‚û°Ô∏è one Deploy.</strong> This will inevitably lead to more deployments because now you might have to do ten deployments to match your big dump releases of the past. This is good! The more you deploy, the less scary it is.</p>

<p>Deploying small changes also gives you better visibility into how your code is affecting the service. <strong>By releasing one change at a time, developers can use telemetry to observe how the code behaves in production and spot bugs before your users do</strong>. In contrast, if you batch multiple PRs in a single deploy, you might have a harder time figuring out which of the changes caused the issue. You might even have to convince the developer that what caused the issue is indeed their commit and not somebody else‚Äôs bundled together in the same release. You can avoid all this hassle by following the ‚Äúone PR ‚û°Ô∏è one Deploy‚Äù rule.</p>

<p>And the benefits don‚Äôt end there! Smaller changes also mean shorter code reviews. It‚Äôs easier for developers reviewing your code to spot bugs in a small PR than in a huge one that modifies hundreds of lines. This is another way in which smaller changes bring better code quality.</p>

<p><img class="center" src="/images/posts/2021-01-22/huge-pr.jpeg" width="400"></p>

<p>Last but not least, smaller PRs produce short-lived branches, reducing the number of merge conflicts one has to deal with.</p>

<h2>Deploying != Releasing</h2>

<p>For this approach to work, you need to trust devs with the keys to production. Depending on how your team operates, this might sound risky. <em>Are you saying developers can put code in production whenever they want?</em> Yes! That‚Äôs exactly what we‚Äôre advocating for. As pointed out earlier, this will mean more deploys, but it‚Äôs generally safer than the humongous release approach. Even if it feels like you lose control of what goes out the door. Yes, you‚Äôll be deploying bugs from time to time, but the blast radius is limited, and the change is easier to rollback.</p>

<p><strong>Now, this doesn‚Äôt mean that all users are immediately able to see the new changes as soon as you deploy.</strong> The terms <em>deploy</em> and <em>release</em> are sometimes used interchangeably, so let‚Äôs define how we‚Äôll use them here:</p>

<ul>
<li><strong>Deploy:</strong> Put a new version of the code in production.</li>
<li><strong>Release:</strong> Make some functionality available to users.</li>
</ul>


<p>You can (and should) still control at what rate new functionality is released to users. You might use a rollout strategy where only a subset of power-users get to see what you‚Äôre working on and provide feedback before the feature is released to a broader audience. Or, you might want to start by observing how it works on a small percentage of users and then gradually roll out to everyone else. You can achieve this by hiding the new code behind <a href="https://martinfowler.com/articles/feature-toggles.html">Feature Flags</a> and have it conditionally enabled. This provides the extra benefit of being able to enable and disable the code with a simple configuration change (without requiring a deploy), should a critical bug be found.</p>

<h2>It‚Äôs not about testing</h2>

<p>One common argument from the <em>‚Äúdeploy on Fridays‚Äù</em> camp is about testing. It goes like this:</p>

<blockquote><p>If you‚Äôre scared of deploying on a Friday, it means you either don‚Äôt have enough tests or your tests are not good enough.</p></blockquote>

<p>I don‚Äôt buy it.</p>

<p>No matter how many tests you have, how good your coverage is, you can‚Äôt be sure you‚Äôre not releasing a bug. In the words of Dijkstra: <em>¬†Program testing can be used to show the presence of bugs, but never to show their absence.</em></p>

<p>Most automated tests are about validating the scenarios the dev can come up with during development. They don‚Äôt account for things we can‚Äôt predict<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. So most testing is limited by the imagination of the person writing the test.</p>

<p>Furthermore, our tests usually run in a fake environment where many of the components are mocked. From service stubs to in-memory databases, we use every trick in the book to <a href="https://jivimberg.io/blog/2020/07/27/effective-testing-reducing-non-determinism/">reduce non-determinism from our tests</a>, but this comes at the cost of test fidelity. Our tests no longer accurately represent what happens in production. This is why we need observability and <a href="https://copyconstruct.medium.com/testing-in-production-the-safe-way-18ca102d0ef1">testing in production</a>. This is why we need to <em>deploy</em> and <em>observe</em> to ensure our code is working as intended.</p>

<h2>Conclusion</h2>

<p>To sum up, deploying is just an additional step of the software lifecycle. <strong>You should deploy any day of the week, providing you‚Äôre willing to stick around to observe how your code behaves in production.¬†</strong> If you just want to deploy, and run home to start the weekend, then maybe <em>don‚Äôt</em>. Because no matter how many tests you have, you haven‚Äôt seen your code running in a real environment yet. In the future, we might have DevOps AI to observe and rollback our changes automatically if something looks weird. Until then, though, you‚Äôre on the hook for making sure your code is working as intended. <em>Especially on Fridays.</em></p>

<p>Piecemeal deployments will help you release faster and will improve your code quality. The idea is counter-intuitive, but it works: you have to do the scary thing over and over until it becomes an uninteresting event. Releasing frequently will help you catch bugs sooner and will make your team more efficient.</p>

<hr />

<p>Many of the ideas in this post are inspired by the podcasts <a href="https://www.heavybit.com/library/podcasts/o11ycast/">Oll1cast</a> and <a href="https://maintainable.fm/">Maintainable</a>, as well as the books <a href="https://www.amazon.com/Software-Engineering-Google-Lessons-Programming/dp/1492082791">Software Engineering at Google</a> and <a href="https://www.oreilly.com/library/view/distributed-tracing-in/9781492056621/">Distributed Tracing in Practice</a>. If you enjoy these topics, go check them out.</p>

<p> <img class="right-fill" src="/images/signatures/signature7.png" width="200" title="‚ÄòMy signature‚Äô" ></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>That‚Äôs what exploratory testing is for, and it‚Äôs a creative endeavor that doesn‚Äôt scale linearly with code.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
